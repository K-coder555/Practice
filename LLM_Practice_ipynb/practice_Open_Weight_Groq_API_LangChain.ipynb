{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOmZwsI1kTrd"
   },
   "source": [
    "#### 다음 실습 코드는 학습 목적으로만 사용 바랍니다. 문의 : audit@korea.ac.kr 임성열 Ph.D.\n",
    "\n",
    "Groq의 빠른 추론 엔진을 LangChain에서 체험하는 코드를 소개합니다.    \n",
    "langchain_groq를 통해 쉽게 연결할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "daSSN5ZSetZl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Using cached langchain_groq-0.3.7-py3-none-any.whl (16 kB)\n",
      "Collecting pymupdf\n",
      "  Using cached pymupdf-1.26.3-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "Collecting pypdf\n",
      "  Using cached pypdf-6.0.0-py3-none-any.whl (310 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Collecting langchain==0.1.14\n",
      "  Using cached langchain-0.1.14-py3-none-any.whl (812 kB)\n",
      "Collecting langchain_community==0.0.30\n",
      "  Using cached langchain_community-0.0.30-py3-none-any.whl (1.9 MB)\n",
      "Collecting openai==1.25.1\n",
      "  Using cached openai-1.25.1-py3-none-any.whl (312 kB)\n",
      "Collecting PyYAML>=5.3\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Using cached sqlalchemy-2.0.43-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Using cached aiohttp-3.12.15-cp311-cp311-win_amd64.whl (453 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.37\n",
      "  Using cached langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1\n",
      "  Using cached langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Collecting numpy<2,>=1\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Collecting pydantic<3,>=1\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Using cached anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Collecting sniffio\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>4\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\workspace\\llm\\agent\\lib\\site-packages (from openai==1.25.1) (4.14.1)\n",
      "Collecting langchain_groq\n",
      "  Using cached langchain_groq-0.3.6-py3-none-any.whl (16 kB)\n",
      "  Using cached langchain_groq-0.3.5-py3-none-any.whl (15 kB)\n",
      "  Using cached langchain_groq-0.3.4-py3-none-any.whl (15 kB)\n",
      "  Using cached langchain_groq-0.3.3-py3-none-any.whl (15 kB)\n",
      "  Using cached langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
      "  Using cached langchain_groq-0.3.1-py3-none-any.whl (15 kB)\n",
      "  Using cached langchain_groq-0.3.0-py3-none-any.whl (15 kB)\n",
      "  Using cached langchain_groq-0.2.5-py3-none-any.whl (15 kB)\n",
      "  Using cached langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
      "Collecting groq<1,>=0.4.1\n",
      "  Using cached groq-0.31.0-py3-none-any.whl (131 kB)\n",
      "Collecting langchain_groq\n",
      "  Using cached langchain_groq-0.2.3-py3-none-any.whl (14 kB)\n",
      "  Using cached langchain_groq-0.2.2-py3-none-any.whl (14 kB)\n",
      "  Using cached langchain_groq-0.2.1-py3-none-any.whl (14 kB)\n",
      "  Using cached langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
      "  Using cached langchain_groq-0.1.10-py3-none-any.whl (14 kB)\n",
      "  Using cached langchain_groq-0.1.9-py3-none-any.whl (14 kB)\n",
      "  Using cached langchain_groq-0.1.8-py3-none-any.whl (14 kB)\n",
      "  Using cached langchain_groq-0.1.6-py3-none-any.whl (14 kB)\n",
      "  Using cached langchain_groq-0.1.5-py3-none-any.whl (11 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.3-cp311-cp311-win_amd64.whl (107 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting aiosignal>=1.4.0\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.6.4-cp311-cp311-win_amd64.whl (46 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Using cached propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Using cached yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Collecting h11>=0.16\n",
      "  Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting packaging<24.0,>=23.2\n",
      "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Using cached orjson-3.11.1-cp311-cp311-win_amd64.whl (131 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Using cached pydantic_core-2.33.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Collecting greenlet>=1\n",
      "  Using cached greenlet-3.2.4-cp311-cp311-win_amd64.whl (299 kB)\n",
      "Requirement already satisfied: colorama in c:\\workspace\\llm\\agent\\lib\\site-packages (from tqdm>4->openai==1.25.1) (0.4.6)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: urllib3, typing-inspection, tqdm, tenacity, soupsieve, sniffio, PyYAML, pypdf, pymupdf, pydantic-core, propcache, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, idna, h11, greenlet, frozenlist, distro, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests, pydantic, marshmallow, jsonpatch, httpcore, beautifulsoup4, anyio, aiosignal, requests-toolbelt, httpx, dataclasses-json, aiohttp, openai, langsmith, groq, langchain-core, langchain-text-splitters, langchain_groq, langchain_community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.43 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.10.0 attrs-25.3.0 beautifulsoup4-4.13.4 certifi-2025.8.3 charset_normalizer-3.4.3 dataclasses-json-0.6.7 distro-1.9.0 frozenlist-1.7.0 greenlet-3.2.4 groq-0.31.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.1.14 langchain-core-0.1.53 langchain-text-splitters-0.0.2 langchain_community-0.0.30 langchain_groq-0.1.5 langsmith-0.1.147 marshmallow-3.26.1 multidict-6.6.4 mypy-extensions-1.1.0 numpy-1.26.4 openai-1.25.1 orjson-3.11.1 packaging-23.2 propcache-0.3.2 pydantic-2.11.7 pydantic-core-2.33.2 pymupdf-1.26.3 pypdf-6.0.0 requests-2.32.4 requests-toolbelt-1.0.0 sniffio-1.3.1 soupsieve-2.7 tenacity-8.5.0 tqdm-4.67.1 typing-inspect-0.9.0 typing-inspection-0.4.1 urllib3-2.5.0 yarl-1.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Agent처럼 별도 다른 버전으로 맞춘 패키지를 별도 가상 환경에서 동작시키기 위한 예시 (다음 코드는 최신 버전에서도 정상 동작함)\n",
    "# 일반적으로 최신 버전으로 지정해야 정상 처리되나, 특정 헤비한 패키지인 경우 하위 버전 종속성 가짐 (예, Crew AI, TensorFlow, PyTorch 등) \n",
    "!pip install langchain_groq pymupdf pypdf beautifulsoup4 requests \\\n",
    "            langchain==0.1.14 \\\n",
    "            langchain_community==0.0.30 \\\n",
    "            openai==1.25.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bo6qR14UoZEu"
   },
   "source": [
    "현재 사용 가능한 주요 모델과 API 제한은 아래와 같습니다.\n",
    "\n",
    "\n",
    "| ID                                     | Requests per Minute | Requests per Day | Tokens per Minute | Tokens per Day |\n",
    "|----------------------------------------|---------------------|------------------|-------------------|----------------|\n",
    "| gemma-7b-it                            | 30                  | 14,400           | 15,000            | 500,000        |\n",
    "| gemma2-9b-it                           | 30                  | 14,400           | 15,000            | 500,000        |\n",
    "| llama-3.1-70b-versatile                | 30                  | 14,400           | 18,000            | 500,000        |\n",
    "| llama-3.1-8b-instant                   | 30                  | 14,400           | 20,000            | 500,000        |\n",
    "| llama-3.2-11b-text-preview             | 30                  | 7,000            | 7,000             | 500,000        |\n",
    "| llama-3.2-11b-vision-preview           | 30                  | 7,000            | 7,000             | 500,000        |\n",
    "| llama-3.2-1b-preview                   | 30                  | 7,000            | 7,000             | 500,000        |\n",
    "| llama-3.2-3b-preview                   | 30                  | 7,000            | 7,000             | 500,000        |\n",
    "| llama-3.2-90b-text-preview             | 30                  | 7,000            | 7,000             | 500,000        |\n",
    "| llama-3.2-90b-vision-preview           | 15                  | 3,500            | 7,000             | 250,000        |\n",
    "| llava-v1.5-7b-4096-preview             | 30                  | 14,400           | 30,000            | (No limit)     |\n",
    "| mixtral-8x7b-32768                     | 30                  | 14,400           | 5,000             | 500,000        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZozwH3G_kPDc"
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq # Groq-LangChain 연결\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcNUf5TCpZTe"
   },
   "source": [
    "간단한 체인을 만들고 실행합니다.\n",
    "\n",
    "https://console.groq.com/keys 에서 키를 생성해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NVj9S2kZeThO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 답변:\n",
      " Groq 엔진의 LLM 추론 속도가 빠른 이유는 다음과 같습니다.\n",
      "\n",
      "Groq 엔진은 특화된 하드웨어 아키텍처를 사용하여 LLM(Large Language Model) 추론을 최적화합니다. 이를 통해 Groq 엔진은 일반적인 CPU보다 훨씬 빠른 추론 속도를 달성할 수 있습니다. 또한, Groq 엔진은 저용량의 메모리와 고성능의 처리 능력을 결합하여 LLM 추론을 더 빠르게 수행할 수 있습니다.\n",
      "\n",
      "따라서, Groq 엔진의 LLM 추론 속도가 빠른 것은 특화된 하드웨어 아키텍처와 저용량의 메모리, 고성능의 처리 능력 등 다양한 요인 때문입니다.\n",
      "\n",
      "⏱️ 처리 시간: 6.58초\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = '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' #기존 groq Key로 여러명이 동시에 동작시키면 차단될 수 있습니다. https://groq.com/ DEV CONSOLE에서 접속하여 여러분의 개별 groq Key를 넣어주세요.\n",
    "\n",
    "import time\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 환경변수로 Groq API Key 설정\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\", \"여기에_본인_KEY를_입력하세요\")\n",
    "\n",
    "# Groq Chat 모델 설정 (텍스트 전용 작업에는 llama3-8b-8192 등 사용 권장)\n",
    "chat = ChatGroq(\n",
    "    temperature=0.1,\n",
    "    model=\"llama3-8b-8192\",  # 또는 \"llama3-70b-8192\"\n",
    ")\n",
    "\n",
    "# 웹 페이지 로드\n",
    "url = \"https://wow.groq.com/why-groq/\"\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "# 예외 처리: 문서가 없을 경우 중단\n",
    "if not docs:\n",
    "    raise ValueError(\"❗ 문서 로드 실패: 페이지에서 내용을 불러올 수 없습니다.\")\n",
    "\n",
    "# 질문 및 프롬프트 구성\n",
    "question = \"Groq 엔진의 LLM 추론 속도가 빠른 이유는 무엇인가요? 한국어로 답변하세요.\"\n",
    "\n",
    "system = \"Answer the question from given contexts. Answer in Korean.\"\n",
    "human = \"\"\"\n",
    "Context: {context}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# 체인 구성\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "chain = prompt | chat | StrOutputParser()\n",
    "\n",
    "# 실행 및 출력\n",
    "start = time.time()\n",
    "result = chain.invoke({\n",
    "    \"context\": docs[0].page_content,\n",
    "    \"question\": question\n",
    "})\n",
    "print(\"🔹 답변:\\n\", result)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\n⏱️ 처리 시간: {end - start:.2f}초\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyM4Yt-fMpoX"
   },
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4F1k171MpoY"
   },
   "source": [
    "요약은 LLM의 아주 중요한 기능 중 하나입니다.   \n",
    "일반적으로, LLM의 Abstractive Summarization은 3개의 방법을 사용합니다.\n",
    "\n",
    "- Stuff : 전체 코퍼스를 하나의 프롬프트에 넣고 요약 생성하기\n",
    "- Map-Reduce : 코퍼스를 청크로 분리하고, 각 청크의 요약을 생성한 뒤 합치기\n",
    "- Refine: 코퍼스를 청크로 분리하고, 순차적으로 읽으며 요약 업데이트하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9vkYtYkMpoa"
   },
   "source": [
    "## Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUemn2D7ikKc"
   },
   "source": [
    "gemma 2 모델을 이용해 요약을 수행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kMmlgYzWMpoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Summarize the following paper in Korean.\\nEmphasize the uniqueness and contribution of the paper.\\nAnswer should be in 10 sentences.\\nPlease Answer in Korean.\\n'),\n",
       " HumanMessage(content=\"\\n\\n [1706.03762] Attention Is All You Need\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\\nDonate\\n\\n\\n\\n\\n\\n > cs > arXiv:1706.03762\\n  \\n\\n\\n\\n\\n\\nHelp | Advanced Search\\n\\n\\n\\n\\nAll fields\\nTitle\\nAuthor\\nAbstract\\nComments\\nJournal reference\\nACM classification\\nMSC classification\\nReport number\\narXiv identifier\\nDOI\\nORCID\\narXiv author ID\\nHelp pages\\nFull text\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nopen search\\n\\n\\n\\n\\n\\n\\nGO\\n\\n\\n\\nopen navigation menu\\n\\n\\nquick links\\n\\nLogin\\nHelp Pages\\nAbout\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComputer Science > Computation and Language\\n\\n\\narXiv:1706.03762 (cs)\\n    \\n\\n\\n\\n\\n  [Submitted on 12 Jun 2017 (v1), last revised 2 Aug 2023 (this version, v7)]\\nTitle:Attention Is All You Need\\nAuthors:Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin View a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors\\nView PDF\\nHTML (experimental)\\n\\nAbstract:The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\\n    \\n\\n\\n \\nComments:\\n15 pages, 5 figures\\n\\n\\nSubjects:\\n\\nComputation and Language (cs.CL); Machine Learning (cs.LG)\\n\\nCite as:\\narXiv:1706.03762 [cs.CL]\\n\\n\\n\\xa0\\n(or \\narXiv:1706.03762v7 [cs.CL] for this version)\\n          \\n\\n\\n\\xa0\\n https://doi.org/10.48550/arXiv.1706.03762\\n\\n\\nFocus to learn more\\n\\n\\n\\n                  arXiv-issued DOI via DataCite\\n\\n\\n\\n\\n\\n\\n\\nSubmission history From: Llion Jones [view email]       [v1]\\n        Mon, 12 Jun 2017 17:57:34 UTC (1,102 KB)\\n[v2]\\n        Mon, 19 Jun 2017 16:49:45 UTC (1,125 KB)\\n[v3]\\n        Tue, 20 Jun 2017 05:20:02 UTC (1,125 KB)\\n[v4]\\n        Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB)\\n[v5]\\n        Wed, 6 Dec 2017 03:30:32 UTC (1,124 KB)\\n[v6]\\n        Mon, 24 Jul 2023 00:48:54 UTC (1,124 KB)\\n[v7]\\n        Wed, 2 Aug 2023 00:41:18 UTC (1,124 KB)\\n\\n\\n\\n \\n\\nFull-text links:\\nAccess Paper:\\n\\n\\nView a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authorsView PDFHTML (experimental)TeX SourceOther Formats\\nview license\\n\\n \\n    Current browse context: cs.CL\\n\\n\\n<\\xa0prev\\n\\n\\xa0 | \\xa0 \\nnext\\xa0>\\n\\n\\nnew\\n | \\nrecent\\n | 2017-06\\n\\n    Change to browse by:\\n    \\ncs\\ncs.LG\\n\\n\\n\\n\\nReferences & Citations\\n\\nNASA ADSGoogle Scholar\\nSemantic Scholar\\n\\n\\n\\n\\n\\n 123 blog links (what is this?)\\n        \\n\\n\\nDBLP - CS Bibliography\\n\\nlisting | bibtex \\n\\nAshish VaswaniNoam ShazeerNiki ParmarJakob UszkoreitLlion Jones …\\n\\n\\na\\nexport BibTeX citation\\nLoading...\\n\\n\\n\\n\\nBibTeX formatted citation\\n×\\n\\n\\nloading...\\n\\n\\nData provided by: \\n\\n\\n\\n\\nBookmark\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\nBibliographic Tools\\n\\nBibliographic and Citation Tools\\n\\n\\n\\n\\n\\n\\nBibliographic Explorer Toggle\\n\\n\\n\\nBibliographic Explorer (What is the Explorer?)\\n\\n\\n\\n\\n\\n\\n\\nConnected Papers Toggle\\n\\n\\n\\nConnected Papers (What is Connected Papers?)\\n\\n\\n\\n\\n\\n\\nLitmaps Toggle\\n\\n\\n\\nLitmaps (What is Litmaps?)\\n\\n\\n\\n\\n\\n\\n\\nscite.ai Toggle\\n\\n\\n\\nscite Smart Citations (What are Smart Citations?)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCode, Data, Media\\n\\nCode, Data and Media Associated with this Article\\n\\n\\n\\n\\n\\n\\nalphaXiv Toggle\\n\\n\\n\\nalphaXiv (What is alphaXiv?)\\n\\n\\n\\n\\n\\n\\n\\nLinks to Code Toggle\\n\\n\\n\\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\\n\\n\\n\\n\\n\\n\\n\\nDagsHub Toggle\\n\\n\\n\\nDagsHub (What is DagsHub?)\\n\\n\\n\\n\\n\\n\\n\\nGotitPub Toggle\\n\\n\\n\\nGotit.pub (What is GotitPub?)\\n\\n\\n\\n\\n\\n\\n\\nHuggingface Toggle\\n\\n\\n\\nHugging Face (What is Huggingface?)\\n\\n\\n\\n\\n\\n\\n\\nLinks to Code Toggle\\n\\n\\n\\nPapers with Code (What is Papers with Code?)\\n\\n\\n\\n\\n\\n\\n\\nScienceCast Toggle\\n\\n\\n\\nScienceCast (What is ScienceCast?)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDemos\\n\\nDemos\\n\\n\\n\\n\\n\\n\\nReplicate Toggle\\n\\n\\n\\nReplicate (What is Replicate?)\\n\\n\\n\\n\\n\\n\\n\\nSpaces Toggle\\n\\n\\n\\nHugging Face Spaces (What is Spaces?)\\n\\n\\n\\n\\n\\n\\n\\nSpaces Toggle\\n\\n\\n\\nTXYZ.AI (What is TXYZ.AI?)\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated Papers\\n\\nRecommenders and Search Tools\\n\\n\\n\\n\\n\\n\\nLink to Influence Flower\\n\\n\\n\\nInfluence Flower (What are Influence Flowers?)\\n\\n\\n\\n\\n\\n\\n\\nCore recommender toggle\\n\\n\\n\\nCORE Recommender (What is CORE?)\\n\\n\\n\\n\\n\\nAuthor\\nVenue\\nInstitution\\nTopic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        About arXivLabs\\n      \\n\\n\\n\\narXivLabs: experimental projects with community collaborators\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhich authors of this paper are endorsers? |\\n    Disable MathJax (What is MathJax?)\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\nHelp\\n\\n\\n\\n\\n\\ncontact arXivClick here to contact arXiv\\n Contact\\n\\n\\nsubscribe to arXiv mailingsClick here to subscribe\\n Subscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopyright\\nPrivacy Policy\\n\\n\\n\\n\\nWeb Accessibility Assistance\\n\\n\\narXiv Operational Status \\n                    Get status notifications via\\n                    email\\n                    or slack\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stuff\n",
    "example_URL='https://arxiv.org/abs/1706.03762'\n",
    "\n",
    "loader = WebBaseLoader(example_URL)\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "gemma2 = ChatGroq(\n",
    "    temperature=0,\n",
    "    model=\"gemma2-9b-it\",\n",
    ")\n",
    "\n",
    "summarize_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''Summarize the following paper in Korean.\n",
    "Emphasize the uniqueness and contribution of the paper.\n",
    "Answer should be in 10 sentences.\n",
    "Please Answer in Korean.\n",
    "'''),\n",
    "    ('user', '''{text}''')])\n",
    "\n",
    "print(len(docs[0].page_content))\n",
    "summarize_prompt.format_messages(text=docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5MOx1k71Mpoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 논문 \"Attention Is All You Need\"는 순환 신경망이나 합성곱 신경망과 같은 복잡한 구조를 사용하지 않고, **단순히 Attention 메커니즘만을 기반으로** 기존의 기계 번역 모델을 뛰어넘는 성능을 보여주는 새로운 네트워크 아키텍처인 Transformer를 제안합니다. \n",
      "\n",
      "이 논문의 가장 큰 혁신은 **RNN이나 CNN을 사용하지 않고도 효과적인 기계 번역 모델을 구축할 수 있다는 것을 증명**한 것입니다. \n",
      "\n",
      "Transformer는 Attention 메커니즘을 통해 입력 시퀀스의 모든 요소 간의 관계를 효과적으로 학습할 수 있기 때문에, **더 빠른 학습 속도와 높은 병렬 처리 능력**을 제공합니다. \n",
      "\n",
      "실험 결과, Transformer는 기존 최고 성능 모델을 뛰어넘는 결과를 보였으며, 특히 **훈련 시간이 훨씬 단축**되는 것을 확인할 수 있습니다. \n",
      "\n",
      "또한, Transformer는 **기계 번역 외에도 문장 구조 분석과 같은 다른 NLP 작업에도 효과적으로 적용**될 수 있음을 보여주었습니다. \n",
      "\n",
      "이 논문은 **Attention 메커니즘의 잠재력을 보여주는 중요한 연구**이며, 이후 다양한 NLP 모델에 큰 영향을 미쳤습니다. \n",
      "\n",
      "결론적으로, Transformer는 **기계 학습 분야에 혁신적인 변화를 가져온** 중요한 논문입니다. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_chain = summarize_prompt | gemma2 | StrOutputParser()\n",
    "summary = summarize_chain.invoke(docs[0].page_content)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCaANqOKMpoa"
   },
   "source": [
    "해당 방법은 매우 간단하지만, Context 길이를 넘어서는 경우 에러가 발생합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLO3VmBdikKd"
   },
   "source": [
    "## Map-Reduce\n",
    "LangChain의 PyMuPdfLoader를 이용하여 임의의 PDF를 요약해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "14r339tyikKd"
   },
   "outputs": [],
   "source": [
    "# # Password 있는 PDF 열기\n",
    "# from langchain.document_loaders import PyPDFLoader\n",
    "# path_material = './paper-attention.pdf'\n",
    "\n",
    "# pypdf_loader = PyPDFLoader(path_material, password='비밀번호')\n",
    "# material_pages = pypdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BqWN9mrkikKd"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "import urllib.request\n",
    "\n",
    "paper_URL = \"https://arxiv.org/pdf/1706.03762\"\n",
    "\n",
    "\n",
    "# 외부 링크에서 PDF 파일을 다운로드하는 코드\n",
    "urllib.request.urlretrieve(\n",
    "    paper_URL,\n",
    "    filename=\"paper-attention.pdf\"\n",
    ")\n",
    "path = './paper-attention.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ImhjYgkqikKd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39498"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "loader = PyMuPDFLoader(path)\n",
    "# 페이지별로 저장\n",
    "pages = loader.load()\n",
    "\n",
    "# 코퍼스에 모두 결합\n",
    "corpus = Document(page_content='')\n",
    "for page in pages:\n",
    "    corpus.page_content += page.page_content\n",
    "len(corpus.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvhDiGhdMpoa"
   },
   "source": [
    "긴 Context를 처리하기 위해, 전체 코퍼스를 작은 단위로 쪼개 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c5pXmAy-Mpoa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000) #chunk_size는 한 chunkdp 포함될 최대 글자수입니다.\n",
    "document_list = text_splitter.split_documents([corpus])\n",
    "len(document_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UE34hmK8Mpoa"
   },
   "source": [
    "이후 Map-Reduce와 Refine을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1rP6f8OMpoa"
   },
   "source": [
    "## Map-Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "itfSciDVMpoa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:06<00:24,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 0\n",
      "본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처는 주어진 문장의 모든 단어들 간의 관계를 파악하기 위해 주의 메커니즘만을 사용하여 기존의 순환 신경망이나 합성곱 신경망을 사용하지 않습니다. \n",
      "\n",
      "Transformer는 인코더와 디코더로 구성되며, 각각은 여러 개의 셀프-어텐션 계층과 포인트 와이즈 풀리 연결 계층으로 이루어져 있습니다. 인코더는 입력 문장을 벡터 형태로 변환하고, 디코더는 이 벡터를 기반으로 출력 문장을 생성합니다. \n",
      "\n",
      "Transformer는 셀프-어텐션을 통해 입력 문장의 모든 단어들 간의 관계를 효과적으로 학습할 수 있습니다. 이는 기존의 순환 신경망이나 합성곱 신경망에 비해 병렬 처리가 가능하며, 훈련 시간을 크게 단축시킬 수 있습니다. \n",
      "\n",
      "실험 결과, Transformer는 기존의 최고 성능 모델을 능가하는 결과를 보였으며, 특히 기존 모델보다 훨씬 짧은 시간 안에 훈련될 수 있다는 장점을 보여주었습니다. \n",
      "\n",
      "결론적으로, Transformer는 뛰어난 성능과 효율성을 제공하는 새로운 신경망 아키텍처이며, 향후 기계 번역 및 기타 자연어 처리 분야에서 폭넓게 활용될 것으로 기대됩니다. \n",
      "\n",
      "\n",
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:27<00:45, 15.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 1\n",
      "본 논문은 Transformer 모델의 핵심 구성 요소인 Self-Attention 메커니즘을 설명하고, 이를 기반으로 구축된 모델의 장점을 다룹니다. \n",
      "\n",
      "먼저, Scaled Dot-Product Attention 알고리즘을 소개하며, 이는 쿼리, 키, 값을 이용하여 각 단어의 중요도를 계산하는 방식을 설명합니다. 이 알고리즘은 dot product를 이용하여 계산 속도와 공간 효율성을 높였으며, softmax 함수를 통해 각 단어의 가중치를 결정합니다. \n",
      "\n",
      "다음으로, Multi-Head Attention을 통해 여러 관점에서 정보를 동시에 처리할 수 있도록 개선된다고 설명합니다. 각 헤드는 독립적으로 작동하며, 여러 헤드의 결과를 결합하여 더 풍부한 정보를 학습할 수 있도록 합니다. \n",
      "\n",
      "논문에서는 Transformer 모델에서 Self-Attention이 사용되는 세 가지 방식을 제시합니다. 첫째, encoder-decoder attention은 디코더의 각 단어가 인코더의 모든 단어에 대해 주의를 기울일 수 있도록 합니다. 둘째, encoder 내부의 Self-Attention은 각 단어가 이전 단어들과의 관계를 학습할 수 있도록 합니다. 셋째, 디코더 내부의 Self-Attention은 각 단어가 이전 단어들과의 관계를 학습하면서도 오른쪽으로만 정보를 흐르도록 제한합니다. \n",
      "\n",
      "또한, Positional Encoding을 통해 순서 정보를 모델에 제공한다고 설명합니다. \n",
      "\n",
      "마지막으로, Self-Attention이 Recurrent와 Convolutional layer보다 뛰어난 성능을 보이는 이유를 설명합니다. Self-Attention은 모든 단어 간의 관계를 효율적으로 학습할 수 있으며, Long-range dependency를 학습하는 데 유리합니다.\n",
      "\n",
      "\n",
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:35<02:22, 47.57s/it]\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jd3jew9veemay6ep0tb2znnz` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 12864, Requested 2574. Please try again in 1.751s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m raw_summaries = []\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(document_list))):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     response = \u001b[43mmap_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     raw_summaries.append(response)\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/runnables/base.py:2499\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config)\u001b[39m\n\u001b[32m   2497\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2498\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps):\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2500\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2501\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[32m   2502\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2503\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2504\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2506\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   2507\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:158\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    149\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m     **kwargs: Any,\n\u001b[32m    154\u001b[39m ) -> BaseMessage:\n\u001b[32m    155\u001b[39m     config = ensure_config(config)\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    157\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    168\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:560\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    553\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    554\u001b[39m     prompts: List[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    557\u001b[39m     **kwargs: Any,\n\u001b[32m    558\u001b[39m ) -> LLMResult:\n\u001b[32m    559\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:421\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    419\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m    420\u001b[39m             run_managers[i].on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    422\u001b[39m flattened_outputs = [\n\u001b[32m    423\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    425\u001b[39m ]\n\u001b[32m    426\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:411\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    409\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    410\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m         )\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    419\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:632\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    636\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_groq/chat_models.py:250\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    245\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    246\u001b[39m params = {\n\u001b[32m    247\u001b[39m     **params,\n\u001b[32m    248\u001b[39m     **kwargs,\n\u001b[32m    249\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/groq/resources/chat/completions.py:368\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    182\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    183\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    230\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    231\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    233\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/groq/_base_client.py:1232\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1219\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1220\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1227\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1228\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1229\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1230\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1231\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/groq/_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jd3jew9veemay6ep0tb2znnz` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 12864, Requested 2574. Please try again in 1.751s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Map 과정 : 각 문서에 대해 요약을 생성합니다. -> Long Context 인 경우, 균일하게 분할하여 요약하고 다시 합치는 방법으로 성능 개선\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''주어진 논문의 내용을 읽고 한국어로 요약하세요.\n",
    "요약은 1개의 문단과 문단별 6개의 문장으로 작성하세요.\n",
    "답변은 한국어로 작성하세요.\n",
    "같은 내용을 반복하지 마세요.\n",
    "'''),\n",
    "    ('user', '''{text}''')])\n",
    "\n",
    "map_chain  = map_prompt | gemma2 | StrOutputParser()\n",
    "\n",
    "raw_summaries = []\n",
    "for i in tqdm(range(len(document_list))):\n",
    "    response = map_chain.invoke(document_list[i].page_content)\n",
    "    raw_summaries.append(response)\n",
    "    print('')\n",
    "    print('#',i)\n",
    "    print(response)\n",
    "    print('===========================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처는 주어진 문장의 모든 단어들 간의 관계를 파악하기 위해 주의 메커니즘만을 사용하여 기존의 순환 신경망이나 합성곱 신경망을 사용하지 않습니다. \\n\\nTransformer는 인코더와 디코더로 구성되며, 각각은 여러 개의 셀프-어텐션 계층과 포인트 와이즈 풀리 연결 계층으로 이루어져 있습니다. 인코더는 입력 문장을 벡터 형태로 변환하고, 디코더는 이 벡터를 기반으로 출력 문장을 생성합니다. \\n\\nTransformer는 셀프-어텐션을 통해 입력 문장의 모든 단어들 간의 관계를 효과적으로 학습할 수 있습니다. 이는 기존의 순환 신경망이나 합성곱 신경망에 비해 병렬 처리가 가능하며, 훈련 시간을 크게 단축시킬 수 있습니다. \\n\\n실험 결과, Transformer는 기존의 최고 성능 모델을 능가하는 결과를 보였으며, 특히 기존 모델보다 훨씬 짧은 시간 안에 훈련될 수 있다는 장점을 보여주었습니다. \\n\\n결론적으로, Transformer는 뛰어난 성능과 효율성을 제공하는 새로운 신경망 아키텍처이며, 향후 기계 번역 및 기타 자연어 처리 분야에서 폭넓게 활용될 것으로 기대됩니다. \\n\\n\\n\",\n",
       " '본 논문은 Transformer 모델의 핵심 구성 요소인 Self-Attention 메커니즘을 설명하고, 이를 기반으로 구축된 모델의 장점을 다룹니다. \\n\\n먼저, Scaled Dot-Product Attention 알고리즘을 소개하며, 이는 쿼리, 키, 값을 이용하여 각 단어의 중요도를 계산하는 방식을 설명합니다. 이 알고리즘은 dot product를 이용하여 계산 속도와 공간 효율성을 높였으며, softmax 함수를 통해 각 단어의 가중치를 결정합니다. \\n\\n다음으로, Multi-Head Attention을 통해 여러 관점에서 정보를 동시에 처리할 수 있도록 개선된다고 설명합니다. 각 헤드는 독립적으로 작동하며, 여러 헤드의 결과를 결합하여 더 풍부한 정보를 학습할 수 있도록 합니다. \\n\\n논문에서는 Transformer 모델에서 Self-Attention이 사용되는 세 가지 방식을 제시합니다. 첫째, encoder-decoder attention은 디코더의 각 단어가 인코더의 모든 단어에 대해 주의를 기울일 수 있도록 합니다. 둘째, encoder 내부의 Self-Attention은 각 단어가 이전 단어들과의 관계를 학습할 수 있도록 합니다. 셋째, 디코더 내부의 Self-Attention은 각 단어가 이전 단어들과의 관계를 학습하면서도 오른쪽으로만 정보를 흐르도록 제한합니다. \\n\\n또한, Positional Encoding을 통해 순서 정보를 모델에 제공한다고 설명합니다. \\n\\n마지막으로, Self-Attention이 Recurrent와 Convolutional layer보다 뛰어난 성능을 보이는 이유를 설명합니다. Self-Attention은 모든 단어 간의 관계를 효율적으로 학습할 수 있으며, Long-range dependency를 학습하는 데 유리합니다.\\n\\n\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ckS-TZVsMpoa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Transformer: 자연어 처리 분야의 혁신적인 신경망 아키텍처\n",
      "\n",
      "본 논문은 자연어 처리 분야에서 혁신적인 성과를 보여주는 새로운 신경망 아키텍처인 Transformer를 소개합니다. Transformer는 기존의 순환 신경망이나 합성곱 신경망을 대체하여, 주어진 문장의 모든 단어들 간의 관계를 파악하는 데 탁월한 성능을 보이는 Self-Attention 메커니즘을 사용합니다. \n",
      "\n",
      "* Transformer는 인코더와 디코더로 구성되며, 각각은 셀프-어텐션 계층과 포인트 와이즈 풀리 연결 계층으로 이루어져 있습니다.\n",
      "* 셀프-어텐션을 통해 Transformer는 입력 문장의 모든 단어들 간의 관계를 효과적으로 학습할 수 있습니다. \n",
      "* 이는 병렬 처리가 가능하여 훈련 시간을 크게 단축시키는 장점을 제공합니다.\n",
      "* 실험 결과, Transformer는 기존 최고 성능 모델을 능가하는 성능을 보였으며, 짧은 시간 안에 훈련될 수 있다는 장점을 보여주었습니다.\n",
      "* Transformer는 Scaled Dot-Product Attention, Multi-Head Attention, Positional Encoding 등의 핵심 구성 요소를 통해 자연어의 복잡한 구조를 효과적으로 학습합니다.\n",
      "\n",
      "결론적으로, Transformer는 뛰어난 성능과 효율성을 제공하는 새로운 신경망 아키텍처로, 기계 번역, 텍스트 요약, 질의응답 등 다양한 자연어 처리 분야에서 폭넓게 활용될 것으로 기대됩니다. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reduce 과정 : 각 문서의 요약을 하나로 합칩니다.\n",
    "reduce_prompt = ChatPromptTemplate.from_messages([\n",
    "\n",
    "    ('system', '''\n",
    "Generate a summary of the following text that includes the following elements:\n",
    "\n",
    "* A title that accurately reflects the content of the text.\n",
    "* An introduction paragraph that provides an overview of the topic.\n",
    "* Bullet points that list the key points of the text.\n",
    "* A conclusion paragraph that summarizes the main points of the text.\n",
    "\n",
    "Answer in Korean.\n",
    "'''),\n",
    "    ('user', '''{text}\n",
    "---\n",
    "요약(In Korean):\n",
    "''')])\n",
    "\n",
    "reduce_chain = reduce_prompt | gemma2 | StrOutputParser()\n",
    "\n",
    "summary = reduce_chain.invoke('\\n---\\n'.join(raw_summaries))\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi84F2cYMpoa"
   },
   "source": [
    "## Refine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZfANrVtMpoa"
   },
   "source": [
    "Refine은 청크를 순서대로 참고하며, 매 시점 요약문을 작성합니다.   \n",
    "요약문과 새로운 청크를 비교하여, 요약문을 업데이트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7dee-KnHMpob"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처가 기존의 순환 신경망(RNN) 기반 모델보다 뛰어난 번역 품질을 달성하면서도 병렬 처리 성능이 뛰어나다는 것을 보여줍니다. Transformer는 주의 메커니즘만을 사용하여 입력과 출력 사이의 글로벌 의존성을 학습하며, 순환 구조 없이 모든 계산을 병렬로 수행할 수 있습니다. \n",
      "\n",
      "* 논문은 기존의 순환 신경망 기반 모델의 한계점을 지적하며, 특히 길어지는 입력/출력 시퀀스에서 병렬 처리의 어려움을 언급합니다.\n",
      "* Transformer는 자기 주의 메커니즘을 기반으로 하며, 입력 시퀀스 내 모든 위치 간의 관계를 효과적으로 학습할 수 있습니다.\n",
      "* Transformer는 인코더와 디코더 스택으로 구성되며, 각 스택은 여러 개의 자기 주의 및 점별 밀집 연결 계층으로 이루어져 있습니다.\n",
      "* 디코더는 인코더의 출력에 대한 주의 메커니즘을 추가하여 이전에 생성된 출력을 활용하여 다음 출력을 생성합니다.\n",
      "* 논문은 Transformer가 기존 모델보다 우수한 번역 성능을 달성하면서도 훨씬 빠른 학습 속도를 보여주는 실험 결과를 제시합니다.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 청크 순서대로 각 청크들을 요약하고, 앞부분 청크 요약과 현재 청크를 연결하여 요약을 업데이트하며 진행한다.\n",
    "# 시간은 오래 걸릴 수 있으나, 청크 업데이트가 잦은 경우에 사용\n",
    "first_summarize_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''당신은 인공지능 전문가입니다.\n",
    "주어진 논문의 내용을 읽고 한국어로 요약하세요.\n",
    "요약은 1개의 문단과 문단별 5개의 문장으로 작성하세요.\n",
    "답변은 한국어로 작성하세요.'''),\n",
    "    ('user', '''{text}''')])\n",
    "\n",
    "\n",
    "\n",
    "X = first_summarize_prompt.format_messages(text=document_list[0])\n",
    "\n",
    "intermediate_summary = gemma2.invoke(X).content\n",
    "print(intermediate_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bBpA1i76Mpob"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:36<01:49, 36.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처가 기존의 순환 신경망(RNN) 기반 모델보다 뛰어난 번역 품질을 달성하면서도 병렬 처리 성능이 뛰어나다는 것을 보여줍니다. Transformer는 주의 메커니즘만을 사용하여 입력과 출력 사이의 글로벌 의존성을 학습하며, 순환 구조 없이 모든 계산을 병렬로 수행할 수 있습니다. \n",
      "\n",
      "Transformer는 **Multi-Head Attention** 이라는 새로운 메커니즘을 사용합니다. 이는 여러 개의 독립적인 \"attention head\"를 병렬로 실행하여 입력 시퀀스 내 모든 위치 간의 관계를 효과적으로 학습합니다. 각 head는  다른 가중치를 가지며, 다양한 정보를 학습하여 전체적인 이해력을 향상시킵니다. \n",
      "\n",
      "또한, Transformer는 **Positional Encoding**을 사용하여 순서 정보를 모델에 직접적으로 주입합니다. 이는 순환 구조나 합성곱 구조가 없는 Transformer가 시퀀스의 순서를 이해하기 위해 필요한 정보를 제공합니다. \n",
      "\n",
      "논문은 Transformer가 기존 모델보다 우수한 번역 성능을 달성하면서 훨씬 빠른 학습 속도를 보여주는 실험 결과를 제시합니다. 특히, Transformer는 RNN 기반 모델보다 훨씬 더 긴 시퀀스를 효율적으로 처리할 수 있습니다. \n",
      "\n",
      "\n",
      "\n",
      "=======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [01:18<01:19, 39.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "본 논문은 'Transformer'라는 새로운 신경망 아키텍처를 소개하며, 이 아키텍처가 기존의 순환 신경망(RNN) 기반 모델보다 뛰어난 번역 품질을 달성하면서도 병렬 처리 성능이 뛰어나다는 것을 보여줍니다. Transformer는 주의 메커니즘만을 사용하여 입력과 출력 사이의 글로벌 의존성을 학습하며, 순환 구조 없이 모든 계산을 병렬로 수행할 수 있습니다. \n",
      "\n",
      "Transformer는 **Multi-Head Attention** 이라는 새로운 메커니즘을 사용합니다. 이는 여러 개의 독립적인 \"attention head\"를 병렬로 실행하여 입력 시퀀스 내 모든 위치 간의 관계를 효과적으로 학습합니다. 각 head는  다른 가중치를 가지며, 다양한 정보를 학습하여 전체적인 이해력을 향상시킵니다. \n",
      "\n",
      "또한, Transformer는 **Positional Encoding**을 사용하여 순서 정보를 모델에 직접적으로 주입합니다. 이는 순환 구조나 합성곱 구조가 없는 Transformer가 시퀀스의 순서를 이해하기 위해 필요한 정보를 제공합니다. \n",
      "\n",
      "Transformer는 RNN 기반 모델보다 훨씬 더 긴 시퀀스를 효율적으로 처리할 수 있으며, 특히, 자체 주의 메커니즘은 RNN 기반 모델보다 더 빠른 속도로 계산될 수 있습니다.  \n",
      "\n",
      "논문은 Transformer가 기존 모델보다 우수한 번역 성능을 달성하면서 훨씬 빠른 학습 속도를 보여주는 실험 결과를 제시합니다. 특히, Transformer는 RNN 기반 모델보다 훨씬 더 긴 시퀀스를 효율적으로 처리할 수 있습니다.  \n",
      "\n",
      "Transformer는 영어 문장 구조 분석과 같은 다른 작업에도 잘 일반화됩니다. \n",
      "\n",
      "\n",
      "\n",
      "=======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [02:01<02:01, 60.96s/it]\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jd3jew9veemay6ep0tb2znnz` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 17288, Requested 3013. Please try again in 21.206s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m refine_chain = refine_prompt | gemma2 | StrOutputParser()\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(document_list))):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     intermediate_summary = \u001b[43mrefine_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprevious_summary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mintermediate_summary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m         \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnew_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdocument_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(intermediate_summary)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/runnables/base.py:2499\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config)\u001b[39m\n\u001b[32m   2497\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2498\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps):\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2500\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2501\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[32m   2502\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2503\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2504\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2506\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   2507\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:158\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    149\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m     **kwargs: Any,\n\u001b[32m    154\u001b[39m ) -> BaseMessage:\n\u001b[32m    155\u001b[39m     config = ensure_config(config)\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    157\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    168\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:560\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    553\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    554\u001b[39m     prompts: List[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    557\u001b[39m     **kwargs: Any,\n\u001b[32m    558\u001b[39m ) -> LLMResult:\n\u001b[32m    559\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:421\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    419\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m    420\u001b[39m             run_managers[i].on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    422\u001b[39m flattened_outputs = [\n\u001b[32m    423\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    425\u001b[39m ]\n\u001b[32m    426\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:411\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    409\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    410\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m         )\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    419\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:632\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    636\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/langchain_groq/chat_models.py:250\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    245\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    246\u001b[39m params = {\n\u001b[32m    247\u001b[39m     **params,\n\u001b[32m    248\u001b[39m     **kwargs,\n\u001b[32m    249\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/groq/resources/chat/completions.py:368\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    182\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    183\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    230\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    231\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    233\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/groq/_base_client.py:1232\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1219\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1220\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1227\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1228\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1229\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1230\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1231\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Eagle/2025_교육-KDT/LLM 실습/llm/lib/python3.11/site-packages/groq/_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `gemma2-9b-it` in organization `org_01jd3jew9veemay6ep0tb2znnz` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 17288, Requested 3013. Please try again in 21.206s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# Refine Prompt\n",
    "\n",
    "refine_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''당신은 인공지능 전문가입니다.\n",
    "논문의 현재 시점까지의 한국어 요약이 주어집니다.\n",
    "이를 읽고, 새롭게 주어지는 내용과 비교하여 한국어 요약을 보완하거나 수정하세요.\n",
    "전체 요약은 10문장 이내로 작성하세요.\n",
    "'''),\n",
    "    ('user', '''현재 시점까지의 요약: {previous_summary}\n",
    "---\n",
    "새로운 내용: {new_text}''')])\n",
    "\n",
    "\n",
    "refine_chain = refine_prompt | gemma2 | StrOutputParser()\n",
    "\n",
    "for i in tqdm(range(1, len(document_list))):\n",
    "    intermediate_summary = refine_chain.invoke(\n",
    "        {'previous_summary':intermediate_summary,\n",
    "         'new_text':document_list[i].page_content})\n",
    "    print('')\n",
    "    print(intermediate_summary)\n",
    "    print('=======================')\n",
    "# 길이를 지정하지 않으면 오래 걸릴 수 있습니다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
